\contentsline {section}{\numberline {1}background knowledge}{2}% 
\contentsline {subsection}{\numberline {1.1}Decision Tree}{2}% 
\contentsline {subsection}{\numberline {1.2}Entropy}{2}% 
\contentsline {subsection}{\numberline {1.3}Conditional Entropy}{3}% 
\contentsline {subsection}{\numberline {1.4}Information Gain}{3}% 
\contentsline {subsection}{\numberline {1.5}Information Gain Ratio}{3}% 
\contentsline {subsection}{\numberline {1.6}Gini Index}{3}% 
\contentsline {section}{\numberline {2}Get Access to Data}{4}% 
\contentsline {section}{\numberline {3}Build a Decition Tree}{4}% 
\contentsline {subsection}{\numberline {3.1}Feature Choice}{4}% 
\contentsline {section}{\numberline {4}Prune the Tree}{4}% 
\contentsline {subsection}{\numberline {4.1}Pre-pruning}{4}% 
\contentsline {subsection}{\numberline {4.2}Post-pruning}{4}% 
\contentsline {subsubsection}{\numberline {4.2.1}REP(Reduced-Error Pruning)}{4}% 
\contentsline {subsubsection}{\numberline {4.2.2}PEP(Pessimistic-Error Pruning)}{5}% 
\contentsline {subsubsection}{\numberline {4.2.3}CCP(Cost-Complexity Pruning)}{5}% 
\contentsline {section}{\numberline {5}Code structure}{5}% 
\contentsline {section}{\numberline {6}Result}{5}% 
\contentsline {subsection}{\numberline {6.1}The Confusion Matrix}{5}% 
